---
sidebar_label: 'llama.cpp'
---

- https://www.reddit.com/r/LocalLLaMA/comments/18s6adh/early_awq_support_added_to_llamacpp/

- https://github.com/ggerganov/llama.cpp/issues/4701

- https://github.com/ggerganov/llama.cpp/pull/5747

- https://github.com/ggerganov/llama.cpp/discussions/5063

- https://www.reddit.com/r/LocalLLaMA/comments/16vknmz/average_bpw_for_gguf_is_much_higher_than_you_think/

- https://www.reddit.com/r/LocalLLaMA/comments/16tgzzk/exllamav2_performance_with_different_quantization/

- https://github.com/ggerganov/llama.cpp/blob/master/examples/quantize/quantize.cpp

Quants

- gguf

- imatrix

- bits per weight (bpw)